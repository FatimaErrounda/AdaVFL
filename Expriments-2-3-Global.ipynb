{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3yxXpClpNkx","executionInfo":{"status":"ok","timestamp":1684514323240,"user_tz":240,"elapsed":18755,"user":{"displayName":"fatima ronda","userId":"15031632683178563098"}},"outputId":"1e6daa48-4665-4772-ad70-95d106ea898f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"b9qiOLt69bVu"},"source":["**Building the data**\n","Useful parameters:\n","\n","\n","*   dataset name, x_axis, y_axis\n","*   input and output length\n","*   train ratio begin and end is used for LocalTrainData, GlobalTrainData\n","*   test ratio begin and end is used for LocalTestData, GlobalTestData\n","*   predictionSampleRatio is used for the local and global prediction datasets?\n","*   trainAttackerBegin is used to train the attacker's model\n","*   train_normalization and test_normalization are for the normalization of the data\n","*   trainingInterval: the size of the batch in terms of time\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kCie7tB9VqO"},"outputs":[],"source":["!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","import numpy as np \n","import os\n","import sys\n","import time\n","import gc\n","import pandas as pd \n","import torch\n","import datetime\n","import tensorflow as tf\n","\n","# notebook_path = os.path.abspath(\"AdaptiveSingleLocalModel.ipynb\")\n","sys.path.append('/content/drive/MyDrive/AdaVFL-GitHub')\n","from Data import MakeTrainingTimes, CheckLocalTrainData, CheckLocalPredictionData, GenerateRandomSamples, LocalSequentialDataset, LocalSampledDataset, GlobalSequentialDataset, GlobalSampledDataset, build_adjMatrix, MakeAttackTimes\n","from federationarguments import arguments\n","\n","args = arguments()\n","if(args.dataset == \"bikeNYC\"):\n","    link = \"https://drive.google.com/drive/folders/1diJwebRNa5AQ16Jy6eHNGtYGmIGeqcrt\"\n","    args.trainingInterval = 24*60*60*1000\n","    args.batch_size = 97\n","    args.overall_size = 2870\n","    args.x_axis = 8\n","    args.y_axis = 16\n","else:\n","    if(args.dataset == \"Yelp\"):\n","        link = \"https://drive.google.com/drive/folders/1K2Y_txKAda0TOEEDYvoa7sPPMYLCXI-U\"\n","        args.trainingInterval = 8*24*60*60*1000\n","        args.batch_size = 32\n","        args.overall_size = 1085\n","        args.x_axis = 8\n","        args.y_axis = 8\n","    else:\n","        raise SystemError('Invalid data folder')  \n","\n","fluff, folder = link.split('folders/')\n","#print (id) \n","filePath = \"'%s' in parents and trashed=false\" %folder\n","print(filePath)\n","downloaded = drive.ListFile({'q':filePath}).GetList()\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  #raise SystemError('GPU device not found')\n","  print('Found GPU at: {}'.format(device_name))\n","  args.device_name = 'cuda'\n","  torch.cuda.set_device(0)\n","else:\n","  args.device_name = 'cpu'\n","\n","LocalTrainData = []\n","LocalValidationData = []\n","LocalTestData = []\n","LocalPredictionSamples = {}\n","GlobalPredictionSamples = GlobalSampledDataset(args)\n","GlobalTestData = GlobalSequentialDataset(args,args.testRatioBegin,args.testRatioEnd)\n","GlobalTrainData = GlobalSequentialDataset(args,args.trainRatioBegin,args.trainRatioEnd)\n","\n","sampled_list = []\n","sampledPrediction = True\n","if len(downloaded) > 0:\n","  sampledPrediction = True\n","  for file in downloaded:\n","    try:\n","        downloaded = drive.CreateFile({'id':file['id']}) \n","        downloaded.GetContentFile(file['title'])  \n","        timestamps = pd.read_csv(file['title'])\n","        grid = file['title'].split(\".\")\n","        axis = grid[0].split(\"X\")\n","        x_axis = int(axis[0])\n","        y_axis = int(axis[1])\n","        train = LocalSequentialDataset(timestamps,x_axis, y_axis, args.trainRatioBegin,args.trainRatioEnd, args)\n","        train.make_data()\n","        LocalTrainData.append(train)\n","\n","        if(sampledPrediction == True):\n","            sampled_list = GenerateRandomSamples(timestamps, args)    \n","            sampledPrediction = False  \n","\n","        predictsample = LocalSampledDataset(timestamps, x_axis, y_axis, args)\n","        predictsample.make_data(sampled_list)\n","        LocalValidationData.append(predictsample)\n","        LocalValidationData.append(predictsample)\n","        test = LocalSequentialDataset(timestamps,x_axis, y_axis, args.testRatioBegin,args.testRatioEnd, args)\n","        test.make_data()\n","        LocalTestData.append(test)\n","        sample_ID = str(x_axis)+\"X\"+str(y_axis)\n","        LocalPredictionSamples[sample_ID] = predictsample\n","        GlobalTestData.add_data(sample_ID, timestamps)\n","        GlobalTrainData.add_data(sample_ID, timestamps)\n","        GlobalPredictionSamples.add_data(sample_ID, predictsample)\n","    except Exception as e:\n","        print(\"hit an exception when making data \",e)\n","        exit('hit an exception when making data')    \n","\n","GlobalTestData.make_data()\n","GlobalTestData.check_data()\n","\n","GlobalTrainData.make_data()\n","GlobalTrainData.check_data()\n","\n","MakeTrainingTimes(LocalTrainData, args)\n","\n","CheckLocalTrainData(LocalTrainData, args)\n","\n","adj = build_adjMatrix(args)\n","\n","del sampled_list\n","del timestamps\n","gc.collect()\n"]},{"cell_type":"markdown","metadata":{"id":"_CYMxVcCmk1c"},"source":["**Privacy budget common initialization for all solutions**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0iIuBZKHmn0n"},"outputs":[],"source":["from Data import generate_local_prediction, build_map,build_adjMatrix\n","from Models import GRU, MyGAT\n","import random\n","from WeightTools import (pertub_weights_process_conc,pertub_weights_process_val,pertub_weights_process_inc,\n","                         pertub_weights_process_ada, rho_to_sigma, sigma_to_rho,compute_advcomp_sigma, \n","                         compute_advcomp_budget, rho_to_dp,compute_cumulated_budget, output_results, update_weights, \n","                         pertub_weights, update_global_weights, Pair, test_model, update_budget_training, \n","                         update_budget_accuracy , update_budget_increase, calculate_validation_accuracy,  \n","                         dp_to_zcdp, grad_func, noisyMax, perturb_gradients, compute_epsilon,\n","                         build_candidates, loss_score, override_model, grad_avg, sigma_to_epsilon, epsilon_to_sigma)\n","from tqdm import tqdm\n","import datetime\n","\n","ratio = 1.\n","contribution = 1.\n","args.tracked_error = []\n","initial_budgets = 0.\n","\n","beginningTime = args.beginTrainingTimestamp\n","endingTime = args.endTrainingTimestamp\n","iterations = args.epochs*(((endingTime - beginningTime)//args.trainingInterval)+1)\n","\n","if args.PrivacyMode != \"None\":\n","  total_epsilon = args.epsilon_0\n","  total_delta = args.delta_0\n","  total_rho = dp_to_zcdp(args.epsilon_0,args.delta_0)\n","  args.total_rho = total_rho\n","  rho_t = total_rho/iterations\n","  sigma_t = rho_to_sigma(rho_t)\n","  delta_t = total_delta/iterations\n","  epsilon_t = rho_to_dp(rho_t,delta_t)\n","  if args.PrivacyMode == \"Uniform\" or args.PrivacyMode == \"Validation\": \n","    initial_budgets=sigma_t\n","  else:\n","    if args.PrivacyMode == \"Increase\":\n","      initial_budgets=epsilon_t\n","    else:\n","      if args.PrivacyMode == \"Concentrated\" or args.PrivacyMode == \"Adaptive\" :\n","        initial_budgets=rho_t"]},{"cell_type":"markdown","metadata":{"id":"ROC3-f0xJZTz"},"source":["**Initialize common variables**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IFvBf3RyJcOl"},"outputs":[],"source":["assigned_epsilon = []\n","assigned_sigma = []\n","assigned_rho = []\n","cumulated_budget = 0.\n","number_of_training_rounds = 0\n","\n","exec_average_local_training_loss = []\n","exec_average_local_RMSE = []\n","exec_average_local_WMAPE = []\n","exec_average_local_AE = []\n","local_training_accuracy_AE = []\n","local_training_accuracy_WMAPE = []\n","local_training_accuracy_RMSE = []\n","local_training_loss = []\n","local_loss_min = 1.\n","local_loss = 1.\n","Min_Loss_trashold = 0.016\n","\n","device_model = GRU(args)"]},{"cell_type":"markdown","metadata":{"id":"Y2qhX1hK9oUH"},"source":["**Global model training and testing with fixed epochs**\n","\n"]},{"cell_type":"code","source":["from Models import  GRU, MyGAT\n","from tqdm import tqdm\n","import copy\n","import random \n","from Data import generate_local_prediction, build_map,build_adjMatrix\n","\n","import datetime\n","import ast\n","import torch.multiprocessing as mp\n","\n","device_models = []\n","global_test_output=[]\n","minimum_training_accuracy = []\n","Loop_accuracy = []\n","privacy_budgets = []\n","\n","for data in LocalTrainData:\n","  if(args.local_model == 'GRU'):\n","    model = GRU(args)\n","    #for the parallelism\n","    model.share_memory() \n","    model.train()\n","  else:\n","    exit('Error: unrecognized local model')  \n","  device_models.append(model)\n","  privacy_budgets.append(initial_budgets)\n","\n","if args.PrivacyMode != \"None\":\n","    for i in range(len(device_models)):\n","      device_models[i].InitializeBudget(privacy_budgets[i])\n","\n","\n","# instantiate the global model to train:\n","if(args.global_model == 'GNN'):\n","  globalModel = MyGAT(args,adj) \n","  globalModel.train()\n","else:\n","  exit('Error: unrecognized global model')\n","\n","# initialize variables for the training:\n","start_time = time.time()\n","global_training_loss = []\n","global_training_accuracy_loss_RMSE = []\n","global_training_accuracy_loss_WMAPE = []\n","global_training_accuracy_loss_AE = []\n","local_training_accuracy = [[]]\n","local_training_accuracy = np.full((len(device_models),iterations),0.)\n","local_training_loss = [[]]\n","local_training_loss = np.full((len(device_models),iterations),0.)\n","average_local_training_loss = []\n","average_local_training_loss = np.full(len(device_models),0.)\n","## device side, training locally\n","weight_dict = {}\n","assigned_budget = [[]]\n","assigned_budget = np.full((len(device_models),iterations),0.)\n","minimum_training_accuracy = []\n","minimum_training_accuracy = np.full(len(device_models),0.)\n","total_budget = []\n","total_budget = np.full(len(device_models),0.)\n","\n","# global_loss_epoch = 10\n","\n","mp.set_start_method('fork')\n","number_of_iterations = ((endingTime - beginningTime)//args.trainingInterval)+1\n","number_of_training_rounds = 0 \n","args.Halt = False\n","for epoch in tqdm(range(args.epochs)):\n","# while args.Halt == False:    \n","  for k in tqdm(range(number_of_iterations)):\n","    timestamp = random.randrange(beginningTime, endingTime, args.trainingInterval)\n","    # iterate over the dataset    \n","    # start the parallelism\n","    quotient = number_of_training_rounds // args.epoch_period\n","    remainder = number_of_training_rounds % args.epoch_period \n","    processes = []\n","    \n","    weight_dict[timestamp] = []\n","\n","    # iterate over the local models\n","    for i in range(len(device_models)):\n","      # train the local model\n","      device_models[i].train()\n","    \n","      if args.PrivacyMode == \"None\":  \n","        p = mp.Process(target=update_weights, args=(timestamp, LocalTrainData[i], device_models[i], args))\n","      else:\n","        if args.PrivacyMode ==  \"Uniform\":  \n","          p = mp.Process(target=pertub_weights, args=(timestamp, LocalTrainData[i], device_models[i],privacy_budgets[i],args))\n","        else:\n","          if args.PrivacyMode ==  \"Validation\":  \n","            p = mp.Process(target=pertub_weights_process_val, args=(timestamp, LocalTrainData[i],LocalValidationData[i], device_models[i],quotient, remainder,args))  \n","          else:\n","            if args.PrivacyMode ==  \"Increase\":  \n","              p = mp.Process(target=pertub_weights_process_inc, args=(timestamp, LocalTrainData[i],device_models[i],delta_t,quotient, remainder,args))      \n","            else:\n","              if args.PrivacyMode ==  \"Concentrated\":  \n","                p = mp.Process(target=pertub_weights_process_conc, args=(timestamp, LocalTrainData[i],LocalValidationData[i], device_models[i],delta_t,number_of_training_rounds,args))      \n","              else:\n","                if args.PrivacyMode ==  \"Adaptive\":  \n","                  p = mp.Process(target=pertub_weights_process_ada, args=(timestamp, LocalTrainData[i],device_models[i],quotient,remainder,number_of_training_rounds,args))          \n","      p.start()\n","      processes.append(p)\n","    for p in processes:\n","      p.join()\n","    \n","    for i in range(len(device_models)):\n","      device_models[i].eval()\n","      weight_dict[timestamp].append(Pair(LocalTrainData[i].x_axis, LocalTrainData[i].y_axis,device_models[i]))  \n","    \n","    # train the global model\n","    number_of_training_rounds += 1\n","    torch.cuda.empty_cache()\n","    weights = weight_dict[timestamp]\n","    predictiondata = {}\n","    with torch.no_grad():\n","      for weight_pair in weights:\n","        sample_ID = str(weight_pair.x_axis)+\"X\"+str(weight_pair.y_axis)\n","        predictiondataset = LocalPredictionSamples.get(sample_ID)\n","        predictiondata[sample_ID]= generate_local_prediction(weight_pair,predictiondataset,args)\n","      PredictionGlobalMap = build_map(predictiondata,args)\n","    global_acc_epoch,global_loss_epoch = update_global_weights(globalModel,GlobalPredictionSamples,PredictionGlobalMap,args,adj)      \n","    global_training_loss.append(global_loss_epoch)\n","    print(\"global_loss_epoch:\",global_loss_epoch)\n","    global_training_accuracy_loss_RMSE.append(global_acc_epoch[\"RMSE\"])\n","    global_training_accuracy_loss_WMAPE.append(global_acc_epoch[\"WMAPE\"])\n","    global_training_accuracy_loss_AE.append(global_acc_epoch[\"AE\"])\n","    del PredictionGlobalMap\n","    del predictiondata\n","    gc.collect()\n","\n","global_acc_training_RMSE = sum(global_training_accuracy_loss_RMSE) / len(global_training_accuracy_loss_RMSE)\n","global_acc_training_WMAPE = sum(global_training_accuracy_loss_WMAPE) / len(global_training_accuracy_loss_WMAPE)\n","global_acc_training_AE = sum(global_training_accuracy_loss_AE) / len(global_training_accuracy_loss_AE)\n","\n","### testing the global model: \n","globalModel.eval() \n","global_test_output, test_acc, test_loss = test_model(globalModel, adj, GlobalTestData,args)\n","print(\"global RMSE\",test_acc[\"RMSE\"],\"global WMAPE\",test_acc[\"WMAPE\"],\"global AE\",test_acc[\"AE\"])\n","print(\"global test_loss\",test_loss) "],"metadata":{"id":"dOzD-iSovdcv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Global model training and testing with fixed budget**"],"metadata":{"id":"ukTS4CCkygyb"}},{"cell_type":"code","source":["from Models import  GRU, MyGAT\n","from tqdm import tqdm\n","import copy\n","import random \n","from Data import generate_local_prediction, build_map,build_adjMatrix\n","\n","import datetime\n","import ast\n","import torch.multiprocessing as mp\n","\n","device_models = []\n","global_test_output=[]\n","minimum_training_accuracy = []\n","Loop_accuracy = []\n","privacy_budgets = []\n","\n","for data in LocalTrainData:\n","  if(args.local_model == 'GRU'):\n","    model = GRU(args)\n","    #for the parallelism\n","    model.share_memory() \n","    model.train()\n","  else:\n","    exit('Error: unrecognized local model')  \n","  device_models.append(model)\n","  privacy_budgets.append(initial_budgets)\n","\n","if args.PrivacyMode != \"None\":\n","    for i in range(len(device_models)):\n","      device_models[i].InitializeBudget(privacy_budgets[i])\n","\n","# instantiate the global model to train:\n","if(args.global_model == 'GNN'):\n","  globalModel = MyGAT(args,adj) \n","  globalModel.train()\n","else:\n","  exit('Error: unrecognized global model')\n","\n","# initialize variables for the training:\n","start_time = time.time()\n","global_training_loss = []\n","global_training_accuracy_loss_RMSE = []\n","global_training_accuracy_loss_WMAPE = []\n","global_training_accuracy_loss_AE = []\n","local_training_accuracy = [[]]\n","local_training_accuracy = np.full((len(device_models),iterations),0.)\n","local_training_loss = [[]]\n","local_training_loss = np.full((len(device_models),iterations),0.)\n","average_local_training_loss = []\n","average_local_training_loss = np.full(len(device_models),0.)\n","## device side, training locally\n","weight_dict = {}\n","assigned_budget = [[]]\n","assigned_budget = np.full((len(device_models),iterations),0.)\n","minimum_training_accuracy = []\n","minimum_training_accuracy = np.full(len(device_models),0.)\n","total_budget = []\n","total_budget = np.full(len(device_models),0.)\n","\n","# global_loss_epoch = 10\n","\n","mp.set_start_method('fork')\n","number_of_iterations = ((endingTime - beginningTime)//args.trainingInterval)+1\n","number_of_training_rounds = 0 \n","\n","Halt = False\n","while Halt == False:  \n","  if args.featureMode == \"None\" or args.featureMode ==  \"Uniform\":\n","    if number_of_training_rounds >= (args.epoch_period*number_of_iterations) :\n","      Halt = True\n","  for i in tqdm(range(number_of_iterations)):\n","    timestamp = random.randrange(beginningTime, endingTime, args.trainingInterval)\n","    # iterate over the dataset    \n","    # start the parallelism\n","    quotient = number_of_training_rounds // args.epoch_period\n","    remainder = number_of_training_rounds % args.epoch_period \n","    processes = []\n","    \n","    weight_dict[timestamp] = []\n","\n","    # iterate over the local models\n","    for i in range(len(device_models)):\n","      # train the local model\n","      device_models[i].train()\n","    \n","      if args.PrivacyMode == \"None\":  \n","        p = mp.Process(target=update_weights, args=(timestamp, LocalTrainData[i], device_models[i], args))\n","      else:\n","        if args.PrivacyMode ==  \"Uniform\":  \n","          p = mp.Process(target=pertub_weights, args=(timestamp, LocalTrainData[i], device_models[i],privacy_budgets[i],args))\n","        else:\n","          if args.PrivacyMode ==  \"Validation\":  \n","            p = mp.Process(target=pertub_weights_process_val, args=(timestamp, LocalTrainData[i],LocalValidationData[i], device_models[i],quotient, remainder,args))  \n","          else:\n","            if args.PrivacyMode ==  \"Increase\":  \n","              p = mp.Process(target=pertub_weights_process_inc, args=(timestamp, LocalTrainData[i],device_models[i],delta_t,quotient, remainder,args))      \n","            else:\n","              if args.PrivacyMode ==  \"Concentrated\":  \n","                p = mp.Process(target=pertub_weights_process_conc, args=(timestamp, LocalTrainData[i],LocalValidationData[i], device_models[i],delta_t,number_of_training_rounds,args))      \n","              else:\n","                if args.PrivacyMode ==  \"Adaptive\":  \n","                  p = mp.Process(target=pertub_weights_process_ada, args=(timestamp, LocalTrainData[i],device_models[i],quotient,remainder,number_of_training_rounds,args))          \n","      p.start()\n","      processes.append(p)\n","    for p in processes:\n","      p.join()\n","    \n","    for i in range(len(device_models)):\n","      device_models[i].eval()\n","      weight_dict[timestamp].append(Pair(LocalTrainData[i].x_axis, LocalTrainData[i].y_axis,device_models[i]))  \n","    \n","    # train the global model\n","    number_of_training_rounds += 1\n","    torch.cuda.empty_cache()\n","    weights = weight_dict[timestamp]\n","    predictiondata = {}\n","    with torch.no_grad():\n","      for weight_pair in weights:\n","        sample_ID = str(weight_pair.x_axis)+\"X\"+str(weight_pair.y_axis)\n","        predictiondataset = LocalPredictionSamples.get(sample_ID)\n","        predictiondata[sample_ID]= generate_local_prediction(weight_pair,predictiondataset,args)\n","      PredictionGlobalMap = build_map(predictiondata,args)\n","    global_acc_epoch,global_loss_epoch = update_global_weights(globalModel,GlobalPredictionSamples,PredictionGlobalMap,args,adj)      \n","    global_training_loss.append(global_loss_epoch)\n","    print(\"global_loss_epoch:\",global_loss_epoch)\n","    global_training_accuracy_loss_RMSE.append(global_acc_epoch[\"RMSE\"])\n","    global_training_accuracy_loss_WMAPE.append(global_acc_epoch[\"WMAPE\"])\n","    global_training_accuracy_loss_AE.append(global_acc_epoch[\"AE\"])\n","    del PredictionGlobalMap\n","    del predictiondata\n","    gc.collect()\n","\n","global_acc_training_RMSE = sum(global_training_accuracy_loss_RMSE) / len(global_training_accuracy_loss_RMSE)\n","global_acc_training_WMAPE = sum(global_training_accuracy_loss_WMAPE) / len(global_training_accuracy_loss_WMAPE)\n","global_acc_training_AE = sum(global_training_accuracy_loss_AE) / len(global_training_accuracy_loss_AE)\n","\n","### testing the global model: \n","globalModel.eval() \n","global_test_output, test_acc, test_loss = test_model(globalModel, adj, GlobalTestData,args)\n","print(\"global RMSE\",test_acc[\"RMSE\"],\"global WMAPE\",test_acc[\"WMAPE\"],\"global AE\",test_acc[\"AE\"])\n","print(\"global test_loss\",test_loss) "],"metadata":{"id":"RMWNSY2uyicj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Save the global model**"],"metadata":{"id":"Eftpfg7STl9F"}},{"cell_type":"code","source":["import os\n","import sys\n","import torch\n","\n","sys.path.append('/content/drive/MyDrive/AdaVFL-GitHub')\n","\n","ratio = args.featureRatio\n","\n","if args.dataset == \"Yelp\":\n","  directory_name = \"/content/drive/MyDrive/Colab Notebooks/Models/Yelp/\"\n","else:\n","  directory_name = \"/content/drive/MyDrive/Colab Notebooks/Models/BikeNYC/\"\n","\n","if args.PrivacyMode== \"None\":\n","  file_name = \"NoPrivacyGAN.pth\"\n","else:\n","  if args.PrivacyMode== \"Uniform\":\n","    file_name = \"UniformPrivacyGAN.pth\"\n","  else:\n","    if args.PrivacyMode== \"Concentrated\":\n","      file_name = \"ConPrivacyGAN.pth\"\n","    else:\n","      if args.PrivacyMode== \"Adaptive\":\n","        file_name = \"AdaFVPrivacyGAN.pth\"\n","      else:\n","        if args.PrivacyMode== \"Validation\":\n","          file_name = \"ValPrivacyGAN.pth\"\n","        else:\n","          if args.PrivacyMode== \"Increase\":\n","            file_name = \"IncreasePrivacyGAN.pth\"  \n","\n","print('Saving global model...')\n","torch.save(globalModel.state_dict(), directory_name+file_name)\n","print('global saved successfully.')\n"],"metadata":{"id":"GAhwyp-3ToPc"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}